{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random as rd\n",
    "from datetime import datetime\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('figure',dpi=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    980\n",
       "0    980\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels = pd.read_csv(\"set_entrenamiento.csv\", low_memory=False)[['person','label']].head(1960)\n",
    "training_labels['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elegir_columnas_random(columnas,n):\n",
    "    rd.seed(n)\n",
    "    lista_columnas = columnas.copy()\n",
    "    cantidad = rd.randint(4, len(lista_columnas))\n",
    "    columnas_prohibidas = ['person','label','checkout']\n",
    "    for x in range(cantidad):\n",
    "        c = rd.choice(lista_columnas)\n",
    "        if c in columnas_prohibidas:\n",
    "            continue\n",
    "        lista_columnas.remove(c)\n",
    "    return lista_columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search():\n",
    "    n_estimators = [20,30,40,50,60,70]\n",
    "    min_samples_split = [10,20,30,40,50]\n",
    "    n_jobs = [-5,-1]\n",
    "    maximos = []\n",
    "    max_score = 0\n",
    "    for n_est in n_estimators:\n",
    "        for min_sam in min_samples_split:\n",
    "            for n_j in n_jobs:\n",
    "                c=RandomForestClassifier(n_estimators=n_est,min_samples_split=min_sam,n_jobs=n_j,random_state=0,class_weight=\"balanced\",criterion = 'entropy')\n",
    "                dt=c.fit(x_train,y_train)\n",
    "                score=c.score(x_test,y_test)*100\n",
    "                if max_score < score:\n",
    "                    maximos = [n_est,min_sam,n_j]\n",
    "                    max_score = score\n",
    "                #print(\"n_estimators : \"+ str(n_est)+\"; min_samples_split: \"+str(min_sam)+\"; n_job: \"+str(n_j)+\"; SCORE: \"+ str(score))\n",
    "    #print(\"El mejor score fue: \"+str(max_score))\n",
    "    return maximos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actualizar_score(score,arbol_score,mejor_arbol_score,cols):\n",
    "    if score > arbol_score:\n",
    "        arbol_score = score\n",
    "    if score > mejor_arbol_score:\n",
    "        columnas_arbol_mejor_score = cols.copy()\n",
    "        mejor_arbol_score = score\n",
    "        sem = x\n",
    "    return score,arbol_score,mejor_arbol_score,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['person', 'Email', 'Organic', 'Paid', 'Referral', 'Social', 'Unknown',\n",
       "       'ad campaign hit', 'brand listing', 'checkout', 'conversion',\n",
       "       'generic listing', 'lead', 'search engine hit', 'searched products',\n",
       "       'staticpage', 'viewed product', 'visited site', 'promedio dias',\n",
       "       'promedio hora', 'retornos', 'longitud busqueda', 'coincide',\n",
       "       'sessions', 'total_time', 'mean_time_by_session', 'max_session_time',\n",
       "       'mean_events_by_session', 'max_events_by_session',\n",
       "       'days_since_last_session', 'promedio de TFIdf'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data_set.csv\", low_memory = False).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = ['person', 'Email', 'Organic', 'Paid', 'Referral', 'Social', 'Unknown',\n",
    "       'ad campaign hit', 'brand listing', 'checkout', 'conversion',\n",
    "       'generic listing', 'lead', 'search engine hit', 'searched products',\n",
    "       'staticpage', 'viewed product', 'visited site', 'promedio dias',\n",
    "       'promedio hora', 'retornos', 'longitud busqueda', 'coincide',\n",
    "       'sessions', 'total_time', 'mean_time_by_session', 'max_session_time',\n",
    "       'mean_events_by_session', 'max_events_by_session',\n",
    "       'days_since_last_session', 'promedio de TFIdf'] #Deben ser columnas del csv que se pasa con los features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 123\n",
    "predicciones = pd.read_csv(\"trocafone_kaggle_test.csv\", low_memory=False)\n",
    "mejor_arbol_score = 0\n",
    "columnas_arbol_mejor_score = []\n",
    "sem = 0\n",
    "arbol_score = 0\n",
    "for x in range(200):\n",
    "    print(\"Arbol : \"+str(x))\n",
    "    \n",
    "    #Preparo los dataframe\n",
    "    training_labels = pd.read_csv(\"set_entrenamiento.csv\", low_memory=False).head(1960)#la idea es pasar un set que sean mitad 0 y mitad 1 sus labels\n",
    "    labels_predict = pd.read_csv(\"trocafone_kaggle_test.csv\", low_memory=False)\n",
    "    data = pd.read_csv(\"data_set.csv\", low_memory = False)\n",
    "    training_labels = training_labels[['person','label']]\n",
    "    cols = elegir_columnas_random(columnas,x)\n",
    "    data = data[cols]\n",
    "    features = pd.merge(training_labels, data, on='person', how='inner')\n",
    "    features = features.fillna(0)\n",
    "    \n",
    "    #Acomodo los sets de test y entrenamiento\n",
    "    train, test = train_test_split(features,test_size=0.10,random_state=RANDOM_SEED)\n",
    "    features=list(features.columns)\n",
    "    features.remove('person')\n",
    "    features.remove('label')\n",
    "    x_train=train[features]\n",
    "    y_train=train['label']\n",
    "    x_test=test[features]\n",
    "    y_test=test['label']\n",
    "    \n",
    "    #Entreno arbol con los mejores hiperparametros encontrados\n",
    "    mejores_hiperparmetros = grid_search()\n",
    "    n_est= mejores_hiperparmetros[0]\n",
    "    min_sam = mejores_hiperparmetros[1]\n",
    "    n_j= mejores_hiperparmetros[2]\n",
    "    c=RandomForestClassifier(n_estimators=n_est,min_samples_split=min_sam,n_jobs=n_j,random_state=0,class_weight=\"balanced\",criterion = 'entropy')\n",
    "    dt=c.fit(x_train,y_train)\n",
    "    \n",
    "    #Veo los resultados\n",
    "    score=c.score(x_test,y_test)*100\n",
    "    score,arbol_score,mejor_arbol_score,cols = actualizar_score(score,0,mejor_arbol_score,cols)\n",
    "    \n",
    "    #Printeo resultados\n",
    "    print(\"Mejor score hasta ahora: \"+str(mejor_arbol_score))\n",
    "    print(\"Score del arbol: \"+str(x)+\" es \"+str(arbol_score))\n",
    "    print(\"Las columnas fueron :\" +str(cols))\n",
    "    print('#--------------------------------------------------------')\n",
    "    \n",
    "    #Opcional por si se quiere usar un promedio de todos los resultados para predecir\n",
    "    prediccion=pd.merge(labels_predict,data,on='person',how='inner')\n",
    "    prediccion = prediccion.fillna(0)\n",
    "    x_final=prediccion[features]\n",
    "    y_final=c.predict(x_final)\n",
    "    nombre_columna = 'label' +str(x)\n",
    "    prediccion[nombre_columna]=y_final\n",
    "    prediccion = prediccion[['person', nombre_columna]]\n",
    "    predicciones = pd.merge(prediccion,predicciones,on='person',how = 'inner')\n",
    "    \n",
    "#Printeo mejor arbol individual    \n",
    "print('#--------------------------------------------------------')\n",
    "print(\"Mejores columnas: \"+str(columnas_arbol_mejor_score))\n",
    "print(\"Mejor score: \"+str(mejor_arbol_score))\n",
    "print('#--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones.to_csv('../modelos/RandomForestResults_ensamble.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
